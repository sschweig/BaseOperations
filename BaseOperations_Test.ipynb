{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a90358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from sqlalchemy import Column, Integer, Text, Date, Float\n",
    "from geoalchemy2 import Geometry\n",
    "from mappings import EVENT_CODES, EVENT_BASE_CODES, EVENT_ROOT_CODES, MAP_FIPS_TO_ISO2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class RequestHandler:\n",
    "    \"\"\"\n",
    "    Reusable and extensible request handler. \n",
    "    \n",
    "    Todo\n",
    "    ----\n",
    "    Provide more generalized functionality. I.E. the ability to retrieve the\n",
    "    response object directly, as well as the ability to POST messages.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 total: int = 3, \n",
    "                 backoff: float = 0.1, \n",
    "                 redirect: int= 3) -> None:\n",
    "        \"\"\"RequestHandler init function.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        total : int, optional\n",
    "            Total number of times to retry the endpoint when `get_content` is \n",
    "            invoked. The default is 3.\n",
    "        backoff : float, optional\n",
    "            Delay added between consecutive requests in the event an endpoint \n",
    "            fails to respond with a status 200 message. The default is 0.1.\n",
    "        redirect : int, optional\n",
    "            Maximum number of redirects permitted before requests library fails. \n",
    "            The default is 3.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info('Init request handler')\n",
    "        self.sess = requests.Session()\n",
    "        \n",
    "        retries = Retry(\n",
    "            total=total,\n",
    "            backoff_factor=backoff,\n",
    "            redirect=redirect\n",
    "        )\n",
    "        \n",
    "        self.sess.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "        logger.info('Request handler initialized')\n",
    "        \n",
    "    def get_content(self, url: str) -> requests.Response:\n",
    "        \"\"\"Fetch response and return the content of the response object.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url : str\n",
    "            Path to target endpoint.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        resp = self.sess.get(url)\n",
    "        \n",
    "        if resp.status_code==200:\n",
    "            return resp.content\n",
    "        else:\n",
    "            logger.info('Endpoint: {} returned status code: {}'.format(\n",
    "                url, resp.status_code))      \n",
    "        \n",
    "TABLE_NAME = \"threat_table\"\n",
    "Base = declarative_base()\n",
    "\n",
    "class Threat(Base):\n",
    "    \"\"\"SQLalchemy base class for storing and retreiving objects.\n",
    "    \n",
    "    Todo\n",
    "    ----\n",
    "    Decide between Integer and Text for Event Codes.\n",
    "    OPTIMIZATION Consider indexing for increased read performance.\n",
    "    OPTIMIZATION String(n) not text to min. space requirements where possible\n",
    "    \"\"\"\n",
    "    __tablename__ = TABLE_NAME\n",
    "    GLOBALEVENTID = Column(Text, primary_key=True) #A\n",
    "    SQLDATE = Column(Text, nullable=False) #B\n",
    "    EventCode = Column(Text, nullable=False) #Z\n",
    "    EventBaseCode = Column(Text, nullable=False) #AA\n",
    "    EventRootCode = Column(Text, nullable=False) #AB\n",
    "    ActionGeo_FullName = Column(Text, nullable=False) #BA\n",
    "    ActionGeo_CountryCode = Column(Text, nullable=False) #BB\n",
    "    ActionGeo_Lat = Column(Text, nullable=False) #BE\n",
    "    ActionGeo_Long = Column(Text, nullable=False) #BF\n",
    "    ActionGeo_Coords = Column(Geometry('POINT'), nullable=False) # BE + BF\n",
    "    DATEADDED = Column(Text, nullable=False) #BH\n",
    "    SOURCEURL = Column(Text, nullable=False) #BI\n",
    "    \n",
    "class DatabaseHandler:\n",
    "    \"\"\"\n",
    "    Reusable and extensible handler for database connections. \n",
    "    \n",
    "    Todo\n",
    "    ----\n",
    "    Extend fetch functionality to enable queries.\n",
    "    Index database for faster searches\n",
    "    OPTIMIZATION Implement connection pooling functionality for faster concurrent \n",
    "    read/writes.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"DatabaseHandler init function.\n",
    "        \n",
    "        Instatiate connection to Postgres + PostGIS database.\n",
    "        \n",
    "        \"\"\"\n",
    "        logger.info('Init request handler')\n",
    "        db_uri = \"postgresql://{}:{}@{}:5432/{}\".format(\n",
    "            os.environ.get('DB_USER', 'default_user'), \n",
    "            os.environ.get('DB_PW', 'default_pass'), \n",
    "            os.environ.get('DB_HOST', 'localhost'), \n",
    "            os.environ.get('DB_NAME', 'test_db')\n",
    "        )\n",
    "        \n",
    "        self.engine = create_engine(\n",
    "            db_uri\n",
    "        )\n",
    "        \n",
    "        self.conn = self.engine.connect() \n",
    "        Base.metadata.create_all(self.engine)\n",
    "        Session = sessionmaker(bind=self.engine)\n",
    "        self.sess = Session()\n",
    "        \n",
    "        logger.info('Database handler initialized')\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Retrieve contents of database, count the results, and print a few rows.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        res = self.fetch_all()\n",
    "        print('Num rows in db: {}\\n'.format(len(res)))\n",
    "        #logger.info('Num rows in db: {}\\n'.format(len(res)))\n",
    "        \n",
    "        for idx, row in enumerate(res):\n",
    "            if idx>= 50:\n",
    "                break\n",
    "            \n",
    "            print(vars(row))\n",
    "            #logger.info(row)\n",
    "            \n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close the database connection.\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.sess.close()\n",
    "        self.conn.close()\n",
    "        self.engine.dispose()\n",
    "        logger.info('Database connection safely closed.')\n",
    "\n",
    "    def fetch_all(self) -> list:\n",
    "        \"\"\"Return results matching all rows.\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            list of rows retrieved from database.\n",
    "            \n",
    "        Todo\n",
    "        ----\n",
    "        Enable querying for particular data. This is sufficient for demo purposes.\n",
    "        OPTIMIZATION Enable indexing\n",
    "\n",
    "        \"\"\"\n",
    "        test_data = self.sess.query(Threat).all()\n",
    "        return test_data\n",
    "    \n",
    "    def upload(self, gdf: gpd.GeoDataFrame()) -> None:\n",
    "        \"\"\"Populate table with the contents of `gdf`.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gdf : gpd.GeoDataFrame()\n",
    "            Geodataframe containing points of interest within the United States\n",
    "            as well as intel sources, dates, and event codings.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \n",
    "        Todo\n",
    "        ----\n",
    "        OPTIMIZATION Enable caching\n",
    "\n",
    "        \"\"\"\n",
    "        gdf.to_postgis(\n",
    "            TABLE_NAME, \n",
    "            self.engine\n",
    "        )  \n",
    "        \n",
    "        print('Adding {} rows'.format(len(gdf.index)))\n",
    "        logger.info('GeoDataFrame successfully added to table.')\n",
    "        \n",
    "class DataHandler:\n",
    "    \"\"\"\n",
    "    Custom handler for acquiring, prepping, and storing data from `tar_url` and\n",
    "    associated export files.\n",
    "    \n",
    "    Todo\n",
    "    ----\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    tar_url = 'http://data.gdeltproject.org/gdeltv2/lastupdate.txt'\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"DataHandler init function.\n",
    "        \n",
    "        Instantiate DBHandler and RequestHandler classes.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info('Init data handler')\n",
    "        self.db = DatabaseHandler()\n",
    "        self.reqs = RequestHandler()\n",
    "        logger.info('Data handler initialized')\n",
    "        \n",
    "    def run(self) -> None:\n",
    "        pass\n",
    "\n",
    "class RunHandler(DataHandler):\n",
    "    \"\"\"Custom runner use with the `DataHandler` class.    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"RunHandler init function.\n",
    "        \n",
    "        Trigger parent classed initialization.\n",
    "\n",
    "        \"\"\"        \n",
    "        DataHandler.__init__(self)\n",
    "    \n",
    "    \n",
    "    def run(self) -> None:\n",
    "        results = str(self.reqs.get_content(DataHandler.tar_url), 'UTF-8')\n",
    "        urls_list = self._process_latest(results)\n",
    "        print(urls_list)\n",
    "        \n",
    "        '''\n",
    "        Instead of hardcoding (i.e. url = url_list[0]) use list comprehension\n",
    "        plus if statement to find the desired url. This protects against \n",
    "        failures if/when endpoint changes result in the returned list being in\n",
    "        an unexpected order.\n",
    "        '''\n",
    "        url = [url for url in urls_list if 'export' in url][0]\n",
    "        print(url)\n",
    "        \n",
    "        results = io.BytesIO(self.reqs.get_content(url))\n",
    "        \n",
    "        #Unpack zip\n",
    "        df_content = self._extract(results)\n",
    "        print(len(df_content.index))\n",
    "        \n",
    "        #Prep\n",
    "        #gdf = self._data_prep(df_content)\n",
    "        \n",
    "        #Load into db\n",
    "        self.db.upload(gdf)\n",
    "        self.db.test()\n",
    "        self.db.close()\n",
    "    \n",
    "rh = RunHandler()\n",
    "rh.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
